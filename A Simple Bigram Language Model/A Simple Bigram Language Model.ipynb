{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf875a16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.9.0-cp312-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.9 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.pyenv/versions/3.12.4/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in ./.pyenv/versions/3.12.4/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in ./.pyenv/versions/3.12.4/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in ./.pyenv/versions/3.12.4/lib/python3.12/site-packages (from torchvision) (2.2.3)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading pillow-12.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.pyenv/versions/3.12.4/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.9.0-cp312-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.24.0-cp312-cp312-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-12.0.0-cp312-cp312-macosx_11_0_arm64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: mpmath, sympy, pillow, networkx, fsspec, filelock, torch, torchvision\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [torchvision]\u001b[0m [torchvision]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.20.0 fsspec-2025.9.0 mpmath-1.3.0 networkx-3.5 pillow-12.0.0 sympy-1.14.0 torch-2.9.0 torchvision-0.24.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install pytorch\n",
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abbd98bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_of_city</th>\n",
       "      <th>state_code</th>\n",
       "      <th>state_name</th>\n",
       "      <th>dist_code</th>\n",
       "      <th>population_total</th>\n",
       "      <th>population_male</th>\n",
       "      <th>population_female</th>\n",
       "      <th>0-6_population_total</th>\n",
       "      <th>0-6_population_male</th>\n",
       "      <th>0-6_population_female</th>\n",
       "      <th>...</th>\n",
       "      <th>literates_female</th>\n",
       "      <th>sex_ratio</th>\n",
       "      <th>child_sex_ratio</th>\n",
       "      <th>effective_literacy_rate_total</th>\n",
       "      <th>effective_literacy_rate_male</th>\n",
       "      <th>effective_literacy_rate_female</th>\n",
       "      <th>location</th>\n",
       "      <th>total_graduates</th>\n",
       "      <th>male_graduates</th>\n",
       "      <th>female_graduates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abohar</td>\n",
       "      <td>3</td>\n",
       "      <td>PUNJAB</td>\n",
       "      <td>9</td>\n",
       "      <td>145238</td>\n",
       "      <td>76840</td>\n",
       "      <td>68398</td>\n",
       "      <td>15870</td>\n",
       "      <td>8587</td>\n",
       "      <td>7283</td>\n",
       "      <td>...</td>\n",
       "      <td>44972</td>\n",
       "      <td>890</td>\n",
       "      <td>848</td>\n",
       "      <td>79.86</td>\n",
       "      <td>85.49</td>\n",
       "      <td>73.59</td>\n",
       "      <td>30.1452928,74.1993043</td>\n",
       "      <td>16287</td>\n",
       "      <td>8612</td>\n",
       "      <td>7675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Achalpur</td>\n",
       "      <td>27</td>\n",
       "      <td>MAHARASHTRA</td>\n",
       "      <td>7</td>\n",
       "      <td>112293</td>\n",
       "      <td>58256</td>\n",
       "      <td>54037</td>\n",
       "      <td>11810</td>\n",
       "      <td>6186</td>\n",
       "      <td>5624</td>\n",
       "      <td>...</td>\n",
       "      <td>43086</td>\n",
       "      <td>928</td>\n",
       "      <td>909</td>\n",
       "      <td>91.99</td>\n",
       "      <td>94.77</td>\n",
       "      <td>89.00</td>\n",
       "      <td>21.257584,77.5086754</td>\n",
       "      <td>8863</td>\n",
       "      <td>5269</td>\n",
       "      <td>3594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adilabad</td>\n",
       "      <td>28</td>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "      <td>1</td>\n",
       "      <td>117388</td>\n",
       "      <td>59232</td>\n",
       "      <td>58156</td>\n",
       "      <td>13103</td>\n",
       "      <td>6731</td>\n",
       "      <td>6372</td>\n",
       "      <td>...</td>\n",
       "      <td>37660</td>\n",
       "      <td>982</td>\n",
       "      <td>947</td>\n",
       "      <td>80.51</td>\n",
       "      <td>88.18</td>\n",
       "      <td>72.73</td>\n",
       "      <td>19.0809075,79.560344</td>\n",
       "      <td>10565</td>\n",
       "      <td>6797</td>\n",
       "      <td>3768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adityapur</td>\n",
       "      <td>20</td>\n",
       "      <td>JHARKHAND</td>\n",
       "      <td>24</td>\n",
       "      <td>173988</td>\n",
       "      <td>91495</td>\n",
       "      <td>82493</td>\n",
       "      <td>23042</td>\n",
       "      <td>12063</td>\n",
       "      <td>10979</td>\n",
       "      <td>...</td>\n",
       "      <td>54515</td>\n",
       "      <td>902</td>\n",
       "      <td>910</td>\n",
       "      <td>83.46</td>\n",
       "      <td>89.98</td>\n",
       "      <td>76.23</td>\n",
       "      <td>22.7834741,86.1576889</td>\n",
       "      <td>19225</td>\n",
       "      <td>12189</td>\n",
       "      <td>7036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adoni</td>\n",
       "      <td>28</td>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "      <td>21</td>\n",
       "      <td>166537</td>\n",
       "      <td>82743</td>\n",
       "      <td>83794</td>\n",
       "      <td>18406</td>\n",
       "      <td>9355</td>\n",
       "      <td>9051</td>\n",
       "      <td>...</td>\n",
       "      <td>45089</td>\n",
       "      <td>1013</td>\n",
       "      <td>968</td>\n",
       "      <td>68.38</td>\n",
       "      <td>76.58</td>\n",
       "      <td>60.33</td>\n",
       "      <td>15.6322227,77.2728368</td>\n",
       "      <td>11902</td>\n",
       "      <td>7871</td>\n",
       "      <td>4031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  name_of_city  state_code      state_name  dist_code  population_total  \\\n",
       "0      Abohar            3          PUNJAB          9            145238   \n",
       "1    Achalpur           27     MAHARASHTRA          7            112293   \n",
       "2    Adilabad           28  ANDHRA PRADESH          1            117388   \n",
       "3   Adityapur           20       JHARKHAND         24            173988   \n",
       "4       Adoni           28  ANDHRA PRADESH         21            166537   \n",
       "\n",
       "   population_male  population_female  0-6_population_total  \\\n",
       "0            76840              68398                 15870   \n",
       "1            58256              54037                 11810   \n",
       "2            59232              58156                 13103   \n",
       "3            91495              82493                 23042   \n",
       "4            82743              83794                 18406   \n",
       "\n",
       "   0-6_population_male  0-6_population_female  ...  literates_female  \\\n",
       "0                 8587                   7283  ...             44972   \n",
       "1                 6186                   5624  ...             43086   \n",
       "2                 6731                   6372  ...             37660   \n",
       "3                12063                  10979  ...             54515   \n",
       "4                 9355                   9051  ...             45089   \n",
       "\n",
       "   sex_ratio  child_sex_ratio  effective_literacy_rate_total  \\\n",
       "0        890              848                          79.86   \n",
       "1        928              909                          91.99   \n",
       "2        982              947                          80.51   \n",
       "3        902              910                          83.46   \n",
       "4       1013              968                          68.38   \n",
       "\n",
       "   effective_literacy_rate_male  effective_literacy_rate_female  \\\n",
       "0                         85.49                           73.59   \n",
       "1                         94.77                           89.00   \n",
       "2                         88.18                           72.73   \n",
       "3                         89.98                           76.23   \n",
       "4                         76.58                           60.33   \n",
       "\n",
       "                location  total_graduates male_graduates  female_graduates  \n",
       "0  30.1452928,74.1993043            16287           8612              7675  \n",
       "1   21.257584,77.5086754             8863           5269              3594  \n",
       "2   19.0809075,79.560344            10565           6797              3768  \n",
       "3  22.7834741,86.1576889            19225          12189              7036  \n",
       "4  15.6322227,77.2728368            11902           7871              4031  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and pre-process the dataset of indian cities\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "indian_cities_df = pd.read_csv(\"/Users/srinandangondi/Downloads/cities_r2.csv\")\n",
    "\n",
    "indian_cities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ddbfe10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indian_cities_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc885862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove in-line spaces, hypens, and periods\n",
    "indian_cities_df['name_of_city'] = indian_cities_df['name_of_city'].str.replace('[ -.]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1c8edc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abohar', 'achalpur', 'adilabad', 'adityapur', 'adoni']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get city name column, convert to lower-case, and remove trailing white spaces\n",
    "indian_cities_names = indian_cities_df['name_of_city'].str.lower().str.rstrip().tolist()\n",
    "indian_cities_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f0a7381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a b\n",
      "b o\n",
      "o h\n",
      "h a\n",
      "a r\n"
     ]
    }
   ],
   "source": [
    "# print out bigrams of first city name\n",
    "for name in indian_cities_names[:1]:\n",
    "    for c1, c2 in zip(name, name[1:]):\n",
    "        print(c1, c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e2a4338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 26 letters of alphabet, add q to it as no word in our dataset uses it\n",
    "chars = sorted(list(set(''.join(indian_cities_names))))\n",
    "chars = sorted(chars + ['q'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d700ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create letter to index and index to letter look-up dicts\n",
    "c_to_i = {}\n",
    "i_to_c = {}\n",
    "\n",
    "c_to_i['.'] = 0\n",
    "i_to_c[0] = '.'\n",
    "\n",
    "for i, c in enumerate(chars, start=1):\n",
    "    c_to_i[c] = i\n",
    "    i_to_c[i] = c\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea689890",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
      "\n",
      "\n",
      "{0: '.', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n"
     ]
    }
   ],
   "source": [
    "print(c_to_i)\n",
    "print(\"\\n\")\n",
    "print(i_to_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcc10ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fac4ba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8df48d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bigrams for entire dataset and convert them to corresponding indices\n",
    "city_x = []\n",
    "city_y = []\n",
    "\n",
    "for name in indian_cities_names:\n",
    "    name = ['.'] + list(name) + ['.']\n",
    "    for c1, c2 in zip(name, name[1:]):\n",
    "        city_x.append(c_to_i[c1])\n",
    "        city_y.append(c_to_i[c2])        \n",
    "\n",
    "city_x = torch.tensor(city_x)\n",
    "city_y = torch.tensor(city_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b233e67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  ..., 13,  1, 12])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88de9ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2, 15,  ...,  1, 12,  0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "542fc991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert inputs to one hot vectors\n",
    "one_hot_x = torch.nn.functional.one_hot(city_x, num_classes=27).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c194c20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39aa19de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5x27 input\n",
    "# we need 27 neurons each with 27 weights and a bias\n",
    "# define generator for reproducibility\n",
    "\n",
    "g = torch.Generator().manual_seed(365)\n",
    "\n",
    "weights = torch.randn(27,27, generator=g, requires_grad=True)\n",
    "biases = torch.randn(27, generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9973cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 27])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a95193c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1278, -1.9540,  1.8379,  0.3690, -0.6884,  0.4385, -1.1833,  1.0985,\n",
       "        -0.8912,  1.3808, -0.7798,  1.3334,  0.3925,  0.3801, -0.3684,  0.2962,\n",
       "         0.2295, -0.4460, -1.1028, -1.9261, -0.5234, -2.0361,  0.0042,  1.2582,\n",
       "        -1.2097, -0.8044, -0.5702], requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c87e28db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.313628911972046\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "# experiment with # of epochs, learning rate, and regularization constant to get the lowest loss\n",
    "for k in range(500):\n",
    "  \n",
    "  # forward pass\n",
    "  # (5x27) * (27x27) + (27,)\n",
    "  \n",
    "  logits = one_hot_x @ weights + biases\n",
    "  logits_exp = logits.exp() \n",
    "  probs = logits_exp / logits_exp.sum(dim=1, keepdims=True)\n",
    "  \n",
    "  #use L2 regularization with the cross entropy loss function   \n",
    "  loss = -probs[torch.arange(city_x.nelement()), city_y].log().mean() + 0.001*(weights**2).mean()\n",
    "\n",
    "  \n",
    "  # backward pass\n",
    "  weights.grad = None\n",
    "  biases.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "\n",
    "  weights.data -= 5 * weights.grad\n",
    "  biases.data -= 5 * biases.grad\n",
    "\n",
    "print(loss.item())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78e05bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.313628911972046"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e0ffb30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jmbeswarr.\n",
      "sul.\n",
      "puwasfafmyqarhfqheondzj.\n",
      "mbipelysurculopqembalvucgrgvenpalyqyjyfvapurelikgubeshistqumjuqzizumapur.\n",
      "chzjz.\n"
     ]
    }
   ],
   "source": [
    "# sample 5 words from the model\n",
    "for _ in range(5):\n",
    "  \n",
    "  final = []\n",
    "  i = 0\n",
    "  \n",
    "  while True:\n",
    "    \n",
    "    one_hot_x = F.one_hot(torch.tensor([i]), num_classes=27).float()\n",
    "    \n",
    "    logits = one_hot_x @ weights \n",
    "    logits_exp = logits.exp() \n",
    "    probs = logits_exp / logits_exp.sum(1, keepdims=True)\n",
    "\n",
    "    #sample indices of next characters based on probs produced by model     \n",
    "    i = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "    final.append(i_to_c[i])\n",
    "    \n",
    "    #end generating new characters if we encounter '.'     \n",
    "    if i == 0:\n",
    "      break\n",
    "  \n",
    "  print(''.join(final))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
